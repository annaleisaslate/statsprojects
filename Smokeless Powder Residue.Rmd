---
title: "STAT 602 Final Project Smokeless Gunpowder Analysis"
author: "Divanshu Mittal,Angela Rose,Jacob Liester,Anna Leisa Sauser & Hacene Salmi"
date: "4/30/2023"
output:
  word_document: default
  pdf_document: default
  html_document: default
---

```{r  setup, include=FALSE, warning=FALSE }
knitr::opts_chunk$set(echo = F,warning=F,message=F)
```

**Overview:**

In this research, we are doing an analysis of smokeless propellant (powder) used in the creation of small arms. The main purpose of this analysis is to investigate multiple recovered samples from exploded and unexploded IED's to determine the brand of each sample and then compare the results. This analysis consists of two main approaches:

1.  Data exploration of the provided train data and the recovered samples using bar & box plots, histograms, Anova test, and Kruskal-Wallis's analysis.
2.  Building, comparing, and selecting the best multi-class model to predict the brands. The following classification models are used in the analysis:

● LDA

● QDA

● Random Forest

● MClustDA

In addition to the above, we compared the results of the recovered sample 1 and Recovered sample 2 to find out if they are from the same brand or not. Further, for recovered sample 3 and recovered sample 4, we did a separate analysis to find out if more than one brand is used by the manufacturers for making the IEDs.

**Data Description:**

The given training data set has twelve variables, which consist of eight numeric variables and three class variables. The numeric variables are Area, Perim., Major, Minor, Circ., AR, Round, and Solidity and the class variables are Distributor, Brand, and Shape. The data has no missing values. The data contains nine unique distributors, 154 unique brands, and four unique shapes. For data cleaning, we removed the index variable (x).

In addition to the train data set, we were provided with four recovered SAP samples from exploded and un-exploded IEDs. These samples contain only the predictor variables Area, Perim., Major, Minor, Circ., AR, Round, and Solidity.

**Exploratory Data Analysis:**

We started exploratory data analysis by building the bar plot and boxplots. Since there are 154 brands, we used the shape variable as a group to compare the brands across different shapes. We create bar plots for each numeric predictor variable versus Shape to get a better insight into the distribution of data. The boxplots showed that there are numerous outliers in the data and a good amount of separation for the two predictors Major and Minor among shapes categories which means no stronger association with the shape variable while the other variables showed a stronger association.

The bar plot below illustrates the distribution of unique brands among shapes of particles. The cylindrical shape has the highest value followed by flattened_spherical, flake, and spherical shapes.

**Data Split:**

We split the data into 70/30 split by each brand and created a training and test set. We also created a validation set to hyper-tune the parameters of the classification models. The training set consists of 27957 rows while the test data consists of 11987 rows and the validation set consists of 2393 rows.

**Statistical Analysis Techniques:**

We used two techniques to analyze the similarities of the recovered datasets.

**Analysis of Variance (ANOVA)**

Analysis of Variance is a technique that is used to compare the variance in means of the different groups to see if the groups are statistically similar or different. It also analyzes variability within each group. With the null hypothesis being that the recovered samples populations are the same, the Analysis of Variance test returned a very small p-value, indicating that we should reject the null hypothesis, meaning that the difference between the samples is statistically significant. We utilized Tukey's test to validate the results.

**Kruskal-Wallis**

The Kruskal-Wallis test is a test similar to ANOVA. This test is used when the assumptions for ANOVA, like normality, are not met. Kruskal-Wallis uses ranks to calculate a chi-squared test statistic. Similar to our ANOVA test, with the null hypothesis being that the sample populations are the same, the Kruskal-Wallis test returned a very small p-value, indicating that we should reject the null hypothesis, meaning that the difference between the samples is statistically significant. We utilized Dunn's test to validate the results.

**Multi-Classification Techniques:**

**Linear Discriminant Analysis**

In LDA, the goal is to find a straight decision boundary that best separates different classes of data. Since there are more than two classes of Brands in the training set and collinearity in the predictor variables, we started our analysis using the LD model.

We tested three LDA utilizing different transformations of variables and found our best total brand accuracy to be around 29 percent. It predicted nine brands with greater than 80 percent accuracy but does have a 48 percent absolute misclassification rate meaning it was not able to classify some of the brands at all.

**Quadratic Discriminant Analysis**

In QDA, a quadratic equation is used to find a decision boundary that separates different classes of data. Using the variables from the most accurate linear discriminant analysis model, our best total brand accuracy was about 22 percent. It predicted nineteen brands with greater than 80 percent accuracy but does have a 51 percent absolute misclassification rate, which is higher than the linear discriminant analysis.

**Random Forest Classification**

Random forest classification uses many decision trees to create a 'forest'. Each decision tree is made up of nodes (or leaves) and branches. When the data travels through a branch and arrives at a node, that leaf categorizes and splits the data based on the question it is fed. These new groups/sets of data are then sent along another branch to another node, where it is again categorized and split into more groups. This process creates a tree-like structure. Each tree outputs its recommended prediction, and an overall vote is taken to choose the classification prediction.

With a minor tweak in the interactions from our linear discriminant analysis, the random forest model resulted in a total brand accuracy of around 32 percent. It predicted nine brands with an accuracy greater than 80 percent and has a 26 percent absolute misclassification rate, which is lower than both the linear and quadratic discriminant analysis.

**Model-Based Clustering**

Model-based clustering is a statistical approach used to group data points into clusters based on a particular probability distribution, either normal or a mixture of normal. In cluster-based modeling, the number of groups is not predetermined. For this analysis, we used MclustDA model (Discriminant analysis based on Gaussian finite mixture modeling) in which the model is fitted to the data to estimate the parameters of the distribution using maximum likelihood estimation to create clusters.

The MclustDA total brand accuracy was about 24 percent. It predicted sixteen brands with greater than 80 percent accuracy but does have a 55 percent absolute misclassification rate, which is higher than both linear and quadratic discriminant analysis and higher than random forest model.

**Comparison of Models**

We compared the LDA, QDA, Random Forest, and MclustDA models and found that the Random Forest model has the best overall accuracy and the least amount of misclassification. We then used the Random Forest model for making predictions.

**Results validation technique:**

To confirm our predictions for recovered samples we also created a Random Forest model for shape using train data and the variables used for predicting the brands in the selected model above. Our accuracy for shape was 90 percent. The model for shape was helpful in validating our results.

**Predictions/ Results:**

**Part 1: Sample 1 & Sample 2 Analysis:** Comparing the samples to find out if they are from the same brand or from different brands and then finding the brand name.

**Methodology:**

We first applied the selected random forest model on Sample 1 & Sample 2 to predict the brands. Then we took the maximum occurrence of a brand in both samples and compared the results. After that, we validated our results by implementing the LDA model on both samples. In addition to this, we took an extra step to validate our results by predicting shapes using a different random forest model we created in the analysis just for predicting the shapes of the samples.

**Recovered Sample 1:**

Based on the results from the selected Random Forest model, recovered sample 1 has the highest predicted value of 164 and is from Brand Reddot. We validated sample 1 results by implementing the LDA Model and the predicted value of Reddot is the highest with LDA as well. Then we predicted the shape of the recovered sample 1 and the flake has the highest predicted value. We checked the shape of Reddot and it is Flake from the train data, this confirms our results that the recovered sample 1 is from the brand Reddot.

**Recovered Sample 2:**

According to the results from the selected Random Forest model, recovered sample 2 has the highest predicted value of 65 and is from Brand Reddot. We validated sample 2 results by implementing the LDA Model and the predicted value of Reddot is the highest with LDA as well. Then we predicted the shape of the recovered sample 2 and the flake has the highest predicted value. This confirms our results that the recovered sample 2 is from the brand Reddot.

**Part 2: Smokeless Gun Powder presence of multiple Brand Analysis in Sample 3 and Sample 4.**

**Methodology:**

Similarly, like part 1 we first applied the selected random forest model on Sample 1 & Sample 2 to predict the brands. Then we took the five maximum occurrences of the brands in both samples and compared the results. After that, we validated our results by implementing the LDA model on both samples. In addition to this, we took an extra step to validate our results by predicting shapes using a different random forest model we created in the analysis just for predicting the shapes of the samples.

**Recovered Sample 3:**

Based on the results from the selected Random Forest model, recovered sample 3 has the highest predicted value of 61 and is from Brand RamshotEnforcer. We validated sample 3 results by implementing the LDA Model and the predicted value of RamshotEnforcer is the highest with LDA as well. We checked sample 3 for the presence of other brands and both Random Forest and LDA showed the presence of other brands AmericanSelect, AccurateNo.2 and Accurate4100. Then we predicted the shape of the recovered sample 3 and the sample have a spherical and flake shape. This confirmed our analysis that manufacturers are using multiple brands in the recovered sample 3, but the majority of particles are from the brand RamshotEnforcer.

**Recovered Sample 4:**

According to the results from the selected Random Forest model, recovered sample 4 has the highest predicted value of 71 and is from Brand RamshotEnforcer. We validated sample 4 results by implementing the LDA Model and the predicted value of RamshotEnforcer is the highest with LDA as well. We checked sample 4 for the presence of other brands and both Random Forest and LDA showed the presence of other brands AccurateNo.2, Accurate4100 & BL-C(2). Then we predicted the shape of the recovered sample 4 and the sample have spherical and flattened_spherical shape. This confirmed our analysis that manufacturers are using multiple brands in the recovered sample 4, but the majority of particles are from the brand RamshotEnforcer.

**Conclusion:**

The results above indicate that Recovered Sample 1 and Sample 2 are from the same brand ("RedDot"). The table for samples 3 and 4 shows that manufacturers are using multiple brands in the samples. For sample 3, the presence of the following brands Accurate4100, AccurateNo.2, AmericanSelect & RamshotEnforcer are there and in sample 4 Accurate4100, AccurateNo.2, BL-C(2) & RamshotEnforcer brands are found. The majority of the particles are from the brand "RamshotEnforcer" in sample 3 and sample 4 and the common brands in both sample 3 and sample 4 are Accurate4100, AccurateNo.2 & RamshotEnforcer.

#### Importing Libraries

```{r, warning=FALSE}
#Installing required packages and loading libraries

library(ggplot2)
library(GGally)
library(MASS)
library(class)
library(mclust)
library(knitr)
library(dplyr)
library(gridExtra)
library(scales)
library(corrplot)
library(e1071)
library(psych)
library(stats)
library(nnet)
library(randomForest)
```

#### Step1 : Loading the given train data, Missing values Check, Summary of the data & Vizually checking the data.

```{r}
#Reading input data file
sap.train <- read.csv('train.csv', header=TRUE, stringsAsFactor = TRUE)

# Removing the index variable x.
sap.train <- sap.train[,-1]

# Checking dataset format
str(sap.train) 

# Missing Value check in the data 
sum(is.na(sap.train))

#Summary of data
summary(sap.train)

```

Based on the summary output, we can see that the data set consists of 39944 observations and 12 variables distributed as three categorical variables of type factor and eight numeric variables. The data has no missing values, and it contains nine unique distributors, 154 unique brands, and four unique shapes. For data cleaning, we removed the index variable (x).

#### Sub-setting input data based on Shape variable for exploratory data analysis on brands within a Shape. Since there are 154 brands it will be hard to do exploratory data analysis on brands in one step, so we divided the brands by shape and explore the measurements of the brand within a particular Shape.

```{r}
# Creating sub-data sets 
st1 <- subset(sap.train,Shape=="cylindrical")
st2 <- subset(sap.train,Shape=="flake")
st3 <- subset(sap.train,Shape=="flattened_spherical")
st4 <- subset(sap.train,Shape=="spherical")

# Displaying sub-data sets dimensions
dim(st1)
dim(st2)
dim(st3)
dim(st4)

```

#### Step2 a: Exploratory Data Analysis for sap.train data

#### Exploring the data using Box plots.

#### Barplot of unique brands within a Shape (Shape Vs Brand Analysis)

```{r}

# Set Shape types values
Shape_Type <- c("cylindrical","flake","flattened_spherical","spherical")

# Get the unique Brands values used by each Shape
unique_brands_value <- c(length(unique(st1$Brand)),length(unique(st2$Brand)),length(unique(st3$Brand)),length(unique(st4$Brand)))

# Set the dataframe
brands_per_shapes <- data.frame(Shape_Type,unique_brands_value)

# Plotting the unique Brands used by each Shape

ggplot(data=brands_per_shapes, aes(x=Shape_Type, y=unique_brands_value, fill=Shape_Type)) + 
geom_bar(position = 'dodge', stat='identity') +
geom_text(aes(label=unique_brands_value), position=position_dodge(width=0.9), vjust=-0.25)+
ggtitle("Unique Brands values per Shape")+
  theme(plot.title = element_text(hjust = 0.5))
```

The above bar plot shows that the unique brand values belonging to cylindrical and flattened_spherical shapes are greater than flake and spherical.

**Ref:**

-   ggplot2 barplots : Quick start guide - R software and data visualization - Easy Guides - Wiki - STHDA. (2019). Sthda.com. <http://www.sthda.com/english/wiki/ggplot2-barplots-quick-start-guide-r-software-and-data-visualization>

#### Step2b: Box Plots of Measurements of brands within a Shape.

```{r}
# Box plots to show distributions of  Response variable vs numeric Predictors.

ggplot(sap.train, aes(x = Shape, y = Area  , color = Shape)) + geom_boxplot() + ggtitle("Shape VS Area")
ggplot(sap.train, aes(x = Shape, y = Perim., color = Shape)) + geom_boxplot() + ggtitle("Shape VS Perim.")
ggplot(sap.train, aes(x = Shape, y = Major , color = Shape)) + geom_boxplot() + ggtitle("Shape VS Major")
ggplot(sap.train, aes(x = Shape, y = Minor, color = Shape)) + geom_boxplot() + ggtitle("Shape VS Minor")
ggplot(sap.train, aes(x = Shape, y = Circ., color = Shape)) + geom_boxplot() + ggtitle("Shape VS Circ.")
ggplot(sap.train, aes(x = Shape, y = AR, color = Shape)) + geom_boxplot() + ggtitle("Shape VS AR")
ggplot(sap.train, aes(x = Shape, y = Round, color = Shape)) + geom_boxplot() + ggtitle("Shape VS Round")
ggplot(sap.train, aes(x = Shape, y = Solidity, color = Shape)) + geom_boxplot() + ggtitle("Shape VS Solidity")


```

From the above box plots, we can see there are numerous outliers in the data. For the most part, there is not much separation in the box plots which shows that there is a stronger association with the class variable Shape except for the two predictors Major and Minor which show a good amount of separation among shapes categories.

**Ref:**

-   Wickham, H., Chang, W., & Henry, L. (n.d.). A box and whiskers plot (in the style of Tukey). ggplot2.tidyverse. Retrieved 10 March 2023, from <https://ggplot2.tidyverse.org/reference/geom_boxplot.html>
-   Statistics Globe (n.d.). Draw multiple Boxplots in one graph.statisticsglobe .Retrieved 10 March 2023, from <https://statisticsglobe.com/draw-multiple-boxplots-in-one-graph-in-r>

#### Step 3- Hypothesis Testing

#### Importing the four recovered samples.

```{r}
# Recovered Sample1 
recovered.sample1 <- read.csv("recovered.sample.1.csv", header=TRUE, stringsAsFactor = TRUE)
# Recovered Sample2
recovered.sample2 <- read.csv("recovered.sample.2.csv", header=TRUE, stringsAsFactor = TRUE)
# Recovered Sample3
recovered.sample3 <- read.csv("recovered.sample.3.csv", header=TRUE, stringsAsFactor = TRUE)
# Recovered Sample4
recovered.sample4 <- read.csv("recovered.sample.4.csv", header=TRUE, stringsAsFactor = TRUE)
```

#### Analyzing Samples 1 & 2

#### Summary of Exploration of Area Variable

Running both ANOVA and Kruskal-Wallis, and having low values for both in this case, helps strengthen the case that there is evidence of a difference between groups. The evidence against the null hypothesis is strong.

ANOVA p-value: 3.39e-15 Kruskal-Wallis p-value: 2.2e-16

Differences between the p-values exist because of the different mathematical components of ANOVA v. Kruskal-Wallis, but similar p-values with both tests help strengthen our case.

We used Tukey Honestly Significant Difference test after ANOVA to compare the means of all the possible pairs of groups to determine which are significantly different from one another. It controls the family-wise error rate, which is the probability of making at least one type 1 error across the pairwise comparisons.

For Area, the Tukey results tell us that there is a statistically significant difference between the means of Group 2 and Group 1, with Group 2 having a higher mean than Group 1. We can see this echoed in the box plot.

We also used Dunn's test, as a follow-up to our Kruskal-Wallis analysis. Dunn's test has a similar goal of comparing all possible pairs of groups and determining which pairs are significantly different from each other. We used the Holm-Bonferroni correction to adjust the p-values. Again, a very significant difference is shown between Group 1 and Group 2, and the test is highly significant. (See line 15)

#### Summary of Exploration of Perimeter Variable

Similar to Area, Perimeter has a low p-value and our subsequent analyses show significant differences between the two groups.

ANOVA p-value: 3.39e-15 Kruskal-Wallis p-value: 2.2e-16

The difference between those two groups is clearly shown in the boxplot, as well.

#### Summary of Exploration of Major Variable

In the case of Major, the difference between the two groups is less, but still statistically significant. ANOVA p-value: 9.09e-11 Kruskal Wallis p-value: p-value = 1.297e-15

In this case, the Turkey results confirm that the mean in sample 2 is higher than in sample 1, with a difference of 56.26 units and a 95% confidence interval.

And our Dunn's test results confirm sample 2's mean is different from sample 1, with a small p-value and evidence against the null hypothesis.

#### Summary of Minor Variable

Again, both tests show extremely low p-values.

ANOVA p-value: 5.95e-09 Kruskal-Wallis: 1.197e-13

Our Tukey and Dunn's tests tell us there are statistical differences between the means. Though we can see on the boxplot there are more outliers in this variable.

#### Summary of Circ. Variable

Similar to all our tests so far, we find low p-values (in general, values below 0.05 are considered statistically significant) and statistical differences between the means of the two samples. So far, all of these variables are usable and useful.

ANOVA: 0.0294 Kruskal: 0.0003183

#### Summary of AR Variable

In the case of AR, there is not enough evidence to reject the null hypothesis that the means of the groups are equal. We cannot find significant enough differences between samples 1 and 2 to consider them statistically significant.

#### Summary of Round Variable

As with AR, the differences between the two sample groups are not significant enough to be statistically meaningful.

#### Summary of Solidity Variable

As with AR and Round, the Solidity variable between the two groups is too similar to be meaningful or useful for our analysis.

#### Analysis Step 1: Visual inspection of one dataset, getting a "lay of the land," so to speak.

```{r}
#View(recovered.sample1)
```

#### Creating own samples to not interfere with analysis already done.

```{r}
alsample1<-recovered.sample1
alsample2<-recovered.sample2
alsample3<-recovered.sample3
alsample4<-recovered.sample4
```

#### First step:

Explore and compare samples 1 and 2. Visual inspection of histograms to understand the basic shape of the data. Use of both ANOVA for normal data, and use of Kruskal-Wallis for skewed data.

#### Looking at Area in samples 1 and 2.

#### Histograms of Area

```{r}
# Histograms of Area
par(mfrow = c(2, 2))
hist(alsample1$Area)
hist(alsample2$Area)
```

#### Creating a Group Variable

```{r}
alsample1$sample<-1
alsample2$sample<-2
alsample3$sample<-3
alsample4$sample<-4
```

Grouping samples 1 and 2 to compare the two datasets to one another.

```{r}
groupeddata1<-rbind(alsample1, alsample2)
```

```{r}
groupeddata1$sample<-as.factor(groupeddata1$sample)
```

Checking to validate that bind worked for samples 1 and 2.

```{r}
#View(groupeddata1)
```

#### Anova Test

```{r}
# Anova Test 

myanova1<-aov(Area ~sample, groupeddata1)
summary(myanova1)
```

ANOVA shows us the p-value is less than .001, which means there is a significant statistical difference in the average area between the samples. Running Kruskal-Wallis below to verify the findings of ANOVA in the case that the data might be skewed.

#### Kruskal Test

```{r}
# Kruskal Test 
mykruskal1<-kruskal.test(Area ~sample, groupeddata1)
mykruskal1
```

Both ANOVA and Kruskal show very low p-values.

Next, we are running pair-wise analysis and then for Kruskal-Wallis for ANOVA to see which sample areas are significantly different.

```{r}
TukeyHSD(myanova1)
```

#### Box Plot of Area Vs Sample

```{r, warning=FALSE}
boxplot(Area ~sample, groupeddata1)
```

```{r, warning=FALSE}
#load library
#install.packages("FSA")
library(FSA)
#perform Dunn's Test with Bonferroni correction for p-values
dunnTest(Area ~ sample,
         data=groupeddata1,
         method="bonferroni")
```

Above, p.adj is the adjusted value for the Bonferroni method, which multiplies the p-value by the number of tests you're doing. This helps when you're doing multiple tests because they're more likely to make a Type 1 error and reject a null when we should not.

#### Repeating the above analysis for Perimeter in samples 1 and 2.

#### Histograms of Perim.

```{r}
# Histograms of Perim.

par(mfrow = c(2, 2))
hist(alsample1$Perim.)
hist(alsample2$Perim.)
```

#### Anova test

```{r}
# Anova Test 
myanova2<-aov(Perim. ~sample, groupeddata1)
summary(myanova2)
```

Again, very low p-value. Check with Kruskal-Wallis in case the data is skewed, which is visually apparent in sample 2 for Perimeter.

#### Kruskal Test

```{r}
# Kruskal Test
mykruskal2<-kruskal.test(Perim. ~sample, groupeddata1)
mykruskal2
```

```{r}
TukeyHSD(myanova2)
```

#### Box Plot of Perim. Vs Sample

```{r}
boxplot(Perim. ~sample, groupeddata1)
```

```{r, warning=FALSE}
dunnTest(Perim. ~ sample,
         data=groupeddata1,
         method="bonferroni")
```

Again, p-values are low, meaning each has a different perimeter and is individually significant.

#### Looking at Major variable next.

#### Histograms of Major

```{r}
# Histograms of Major

par(mfrow = c(2, 2))
hist(alsample1$Major)
hist(alsample2$Major)
```

#### Anova Test

```{r}
# Anova Test 
myanova3<-aov(Major ~sample, groupeddata1)
summary(myanova3)
```

#### Kruskal Test

```{r}
# Kruskal Test
mykruskal3<-kruskal.test(Major ~sample, groupeddata1)
mykruskal3
```

```{r}
TukeyHSD(myanova3)
```

#### Box Plot of Major Vs Sample

```{r}
boxplot(Major ~sample, groupeddata1)
```

```{r, warning=FALSE}
dunnTest(Major ~ sample,
         data=groupeddata1,
         method="bonferroni")
```

#### Next, looking at the Minor variable in samples 1 and 2.

#### Histograms of Minor

```{r}
# Histograms of Minor

par(mfrow = c(2, 2))
hist(alsample1$Minor)
hist(alsample2$Minor)
```

#### Anova Test

```{r}
#### Anova Test
myanova4<-aov(Minor ~sample, groupeddata1)
summary(myanova4)
```

#### kruskal Test

```{r}
# kruskal Test 
mykruskal4<-kruskal.test(Minor ~sample, groupeddata1)
mykruskal4
```

```{r}
TukeyHSD(myanova4)
```

#### Box plot of Minor Vs Sample

```{r}
boxplot(Minor ~sample, groupeddata1)
```

```{r}
dunnTest(Minor ~ sample,
         data=groupeddata1,
         method="bonferroni")
```

#### Exploring the Circumference variable for samples 1 and 2.

#### Histograms of Circ.

```{r}
# Histograms of Circ.
par(mfrow = c(2, 2))
hist(alsample1$Circ.)
hist(alsample2$Circ.)
```

#### Anova Test

```{r}
#### Anova Test
myanova5<-aov(Circ. ~sample, groupeddata1)
summary(myanova5)
```

#### Kruskal test

```{r}
# Kruskal test
mykruskal5<-kruskal.test(Circ. ~sample, groupeddata1)
mykruskal5
```

#### Box Plot of Circ. Vs Sample

```{r}
boxplot(Circ. ~sample, groupeddata1)
```

```{r}
dunnTest(Circ. ~ sample,
         data=groupeddata1,
         method="bonferroni")
```

#### Looking at AR variable in samples 1 and 2.

#### Histograms of AR

```{r}
# Histograms of AR
par(mfrow = c(2, 2))
hist(alsample1$AR)
hist(alsample2$AR)
```

#### Anova Test

```{r}
# Anova Test
myanova6<-aov(AR ~sample, groupeddata1)
summary(myanova6)
```

#### Kruskal Test

```{r}
# Kruskal Test
mykruskal6<-kruskal.test(AR ~sample, groupeddata1)
mykruskal6
```

```{r}
TukeyHSD(myanova6)
```

#### Box Plot of AR vs Sample

```{r}
boxplot(AR ~sample, groupeddata1)
```

```{r}
dunnTest(AR ~ sample,
         data=groupeddata1,
         method="bonferroni")
```

#### Looking at Round variable in samples 1 and 2.

#### Histograms of Round

```{r}
# Histograms of Round
par(mfrow = c(2, 2))
hist(alsample1$Round)
hist(alsample2$Round)
```

#### Anova Test

```{r}
# Anova Test 
myanova7<-aov(Round ~sample, groupeddata1)
summary(myanova7)
```

#### Kruskal Test

```{r}
# Kruskal Test
mykruskal7<-kruskal.test(Round ~sample, groupeddata1)
mykruskal7
```

```{r}
TukeyHSD(myanova7)
```

#### Box plot of Round Vs Sample

```{r}
boxplot(Round ~sample, groupeddata1)
```

```{r}
dunnTest(Round ~ sample,
         data=groupeddata1,
         method="bonferroni")
```

#### Looking at Solidity in samples 1 and 2.

#### Histograms of Solidity

```{r}
# Histograms of Solidity
par(mfrow = c(2, 2))
hist(alsample1$Solidity)
hist(alsample2$Solidity)
```

#### Anova Test

```{r}
# Anova Test
myanova8<-aov(Solidity ~sample, groupeddata1)
summary(myanova8)
```

#### Kruskal Test

```{r}
# Kruskal Test
mykruskal8<-kruskal.test(Solidity ~sample, groupeddata1)
mykruskal8
```

```{r}
TukeyHSD(myanova8)
```

#### Box Plot of Solidity Vs Sample

```{r}
boxplot(Solidity ~sample, groupeddata1)
```

```{r}
dunnTest(Solidity ~ sample,
         data=groupeddata1,
         method="bonferroni")
```

#### Lastly in the exploratory process, repeat the same procedures (histograms, ANOVA and Kruskal-Wallis) for variables in samples 3 and 4.

Grouping data in samples 3 and 4.

```{r}
groupeddata2<-rbind(alsample3, alsample4)
```

```{r}
groupeddata2$sample<-as.factor(groupeddata2$sample)
```

Checking to validate that bind worked for samples 3 and 4.

```{r}
#View(groupeddata2)
```

Samples 3 & 4

#### Summary of Exploration of Area Variable

Our tests show statistically significant differences between the two groups, and low p-values for Area. Data is more skewed, so relying on Kruskal more than ANOVA.

ANOVA p-value: 2e-16 Kruskal p-value: 6.689e-05

#### Summary of Exploration of Perim. Variable

Low p-values and statistically significant differences in the Perim. variable confirms these are valuable for analysis between samples 3 and 4. Data is skewed, so looking at Kruskal value here.

ANOVA p-value: 2e-16 Kruskal p-value: 4.06e-05

#### Summary of Exploration of Major Variable

As with our other values in samples 3 and 4 groups so far, there are low p-values and significant differences between the two groups.

ANOVA p-value: 2e-16 Kruskal p-value: 3.09e-05

#### Summary of Exploration of Minor Variable

Low p-values and significant differences between the means of each group when looking at the minor variable.

ANOVA p-value: 3.38e-16 Kruskal p-value: 0.0003214

#### Summary of Exploration of Circ. Variable

The data looks skewed in both samples, so we will lean on Kruskal and Dunn's analysis here. Again, low p-values and significant differences between the means make this variable useful for analysis.

ANOVA p-value: 2e-16 Kruskal: 3.388e-07

#### Summary of Exploration of AR Variable

Low p-values and differences between the means make this variable significant.

ANOVA p-value: 2e-16 Kruskal: 2e-16

#### Summary of Exploration of Round Variable

Both sample group variables look skewed, but our analysis gives us low p-values and statistically different means between the samples.

ANOVA p-value: 2e-16 Kruskal: 2e-16

#### Summary of Exploration of Solidity Variable

As with the other values, significant differences between the groups and low p-values.

ANOVA p-value: 6.05e-14 Kruskal: 2.2e-16

#### Area in samples 3 and 4.

#### Histograms of Area

```{r}
# Histograms of Area
par(mfrow = c(2, 2))
hist(alsample3$Area)
hist(alsample4$Area)
```

#### Anova Test

```{r}
# Anova Test
myanova9<-aov(Area ~sample, groupeddata2)
summary(myanova9)
```

#### Kruskal Test

```{r}
# Kruskal Test
mykruskal9<-kruskal.test(Area ~sample, groupeddata2)
mykruskal9
```

```{r}
TukeyHSD(myanova9)
```

#### Box Plot of Area Vs Sample

```{r}
boxplot(Area ~sample, groupeddata2)
```

```{r}
dunnTest(Area ~ sample,
         data=groupeddata2,
         method="bonferroni")
```

#### Perim. in samples 3 and 4.

#### Histograms of Perim.

```{r}
#### Histograms of Perim.
par(mfrow = c(2, 2))
hist(alsample3$Perim.)
hist(alsample4$Perim.)
```

#### Anova Test

```{r}
#### Anova Test
myanova9<-aov(Perim. ~sample, groupeddata2)
summary(myanova9)
```

#### Kruskal Test

```{r}
#### Kruskal Test
mykruskal9<-kruskal.test(Perim. ~sample, groupeddata2)
mykruskal9
```

```{r}
TukeyHSD(myanova9)
```

#### Box Plot of Perim. Vs Sample

```{r}
boxplot(Perim. ~sample, groupeddata2)
```

```{r}
dunnTest(Perim. ~ sample,
         data=groupeddata2,
         method="bonferroni")
```

#### Major variable in samples 3 and 4.

#### Histograms of Major

```{r}
#### Histograms of Major
par(mfrow = c(2, 2))
hist(alsample3$Major)
hist(alsample4$Major)
```

#### Anova Test

```{r}
#### Anova Test
myanova10<-aov(Major ~sample, groupeddata2)
summary(myanova10)
```

#### Kruskal Test

```{r}
#### Kruskal Test
mykruskal10<-kruskal.test(Major ~sample, groupeddata2)
mykruskal10
```

```{r}
TukeyHSD(myanova10)
```

#### Box Plot of Major Vs Sample

```{r}
boxplot(Major ~sample, groupeddata2)
```

```{r}
dunnTest(Major ~ sample,
         data=groupeddata2,
         method="bonferroni")
```

#### Minor variable in samples 3 and 4.

#### Histograms of Minor

```{r}
#### Histograms of Minor
par(mfrow = c(2, 2))
hist(alsample3$Minor)
hist(alsample4$Minor)
```

#### Anova Test

```{r}
#### Anova Test
myanova11<-aov(Minor ~sample, groupeddata2)
summary(myanova11)
```

#### Kruskal Test

```{r}
#### Kruskal Test
mykruskal11<-kruskal.test(Minor ~sample, groupeddata2)
mykruskal11
```

```{r}
TukeyHSD(myanova11)
```

#### Box Plot of Minor Vs Sample

```{r}
boxplot(Minor ~sample, groupeddata2)
```

```{r}
dunnTest(Minor ~ sample,
         data=groupeddata2,
         method="bonferroni")
```

#### Circumference variable in samples 3 and 4.

#### Histograms of Circumference

```{r}
#### Histograms of Circumference
par(mfrow = c(2, 2))
hist(alsample3$Circ.)
hist(alsample4$Circ.)
```

#### Anova Test

```{r}
#### Anova Test
myanova12<-aov(Circ. ~sample, groupeddata2)
summary(myanova12)
```

#### Kruskal Test

```{r}
#### Kruskal Test
mykruskal12<-kruskal.test(Circ. ~sample, groupeddata2)
mykruskal12
```

```{r}
TukeyHSD(myanova12)
```

#### Box Plot of Circ. Vs Sample

```{r}
boxplot(Circ. ~sample, groupeddata2)
```

```{r}
dunnTest(Circ. ~ sample,
         data=groupeddata2,
         method="bonferroni")
```

#### AR variable in samples 3 and 4.

#### Histograms of AR

```{r}
#### Histograms of AR
par(mfrow = c(2, 2))
hist(alsample3$AR)
hist(alsample4$AR)
```

#### Anova Test

```{r}
#### Anova Test
myanova13<-aov(AR ~sample, groupeddata2)
summary(myanova13)
```

#### Kruskal Test

```{r}
#### Kruskal Test
mykruskal13<-kruskal.test(AR ~sample, groupeddata2)
mykruskal13
```

```{r}
TukeyHSD(myanova13)
```

#### Box Plot of AR Vs Sample

```{r}
boxplot(AR ~sample, groupeddata2)
```

```{r}
dunnTest(AR ~ sample,
         data=groupeddata2,
         method="bonferroni")
```

#### Round variable in samples 3 and 4.

#### Histograms of Round

```{r}
#### Histograms of Round
par(mfrow = c(2, 2))
hist(alsample3$Round)
hist(alsample4$Round)
```

#### Anova Test

```{r}
#### Anova Test
myanova14<-aov(Round ~sample, groupeddata2)
summary(myanova14)
```

#### Kruskal Test

```{r}
#### Kruskal Test
mykruskal14<-kruskal.test(Round ~sample, groupeddata2)
mykruskal14
```

```{r}
TukeyHSD(myanova14)
```

#### Box Plot of Round Vs Sample

```{r}
boxplot(Round  ~sample, groupeddata2)
```

```{r}
dunnTest(Round ~ sample,
         data=groupeddata2,
         method="bonferroni")
```

#### Solidity variable in samples 3 and 4.

#### Histograms of Solidity

```{r}
#### Histograms of Solidity
par(mfrow = c(2, 2))
hist(alsample3$Solidity)
hist(alsample4$Solidity)
```

#### Anova Test

```{r}
#### Anova Test
myanova15<-aov(Solidity ~sample, groupeddata2)
summary(myanova15)
```

#### Kruskal Test

```{r}
#### Kruskal Test
mykruskal15<-kruskal.test(Solidity ~sample, groupeddata2)
mykruskal15
```

```{r}
TukeyHSD(myanova15)
```

#### Box Plot of Solidity Vs Sample

```{r}
boxplot(Solidity ~sample, groupeddata2)
```

```{r}
dunnTest(Solidity ~ sample,
         data=groupeddata2,
         method="bonferroni")
```

**Ref:**

-   Bevans, R. (2022). ANOVA in R \| A Complete Step-by-Step Guide with Examples. Scribbr.Retrieved April 22, 2023, from <https://www.scribbr.com/statistics/anova-in-r/>
-   Kruskal-Wallis Test \| R Tutorial. (n.d.). Chi Yau. scribbr. Retrieved April 22, 2023, from <https://www.r-tutor.com/elementary-statistics/non-parametric-methods/kruskal-wallis-test>

#### Step4 Splitting the data set(70,30) based on the Brand Variable in to training and testing data.

```{r}
# splitting the data into train and test set 

# Set the seed
set.seed(1234)

#Get the brands values
brand_list <- unique(sap.train$Brand)

#Set the brands values as a list
levels = levels(brand_list)

#Creating an empty dataframe for training sub-dataset with required columns names
training_dt <- data.frame(matrix(ncol = 13, nrow = 0))

# Set columns names  for training data set 
colnames(training_dt) <- colnames(sap.train)
#Adding seq column to training data set
colnames(training_dt)[13]="seq"

#Creating an empty data frame for test sub-data set with required columns names
testing_dt <- data.frame(matrix(ncol = 13, nrow = 0))
# Set columns names  for test data set 
colnames(testing_dt) <- colnames(sap.train)
#Adding seq column to test data set
colnames(testing_dt)[13]="seq"
 
# Creating training and test data sets based on the brands list
for(i in 1:length(levels)){
  
 #Subset based on the brand list index i
 df_brand <- subset(sap.train,Brand== levels[i] )

 df_brand$seq <- 1:nrow(df_brand)

# Get 70% as sub-training data
 gl_data_train <- df_brand %>% dplyr::sample_frac(0.70)
 
 # Combining the sub-training datasets
 training_dt <-rbind(training_dt, gl_data_train)

 # Get the 30% as sub-testing data
 gl_data_test  <- dplyr::anti_join(df_brand, gl_data_train , by = 'seq')
 
 # Combining the sub-testing datasets
 testing_dt <-rbind(testing_dt, gl_data_test)
}

#Removing seq variable from training & testing 
training_dt <- training_dt[,-12]
testing_dt <- testing_dt[,-12]

#Displaying training and testing datasets dimensions
dim(training_dt)
dim(testing_dt)

# acc_testing_dt <- testing_dt
# fl_testing_df <- testing_dt

```

The training data set has 27957 records, and the testing data has 11987.

#### Step4: Creating a validation data set to hyper-tune the parameters to select the best classifier.

```{r}
# Creating a validation set

# Set the seed
set.seed(1234)

#Creating an empty dataframe for splitting the data  with required columns names
train_dt_va <- data.frame(matrix(ncol = 13, nrow = 0))

# Set columns names  for the data set 
colnames(train_dt_va) <- colnames(testing_dt)
#Adding seq column to the data set
colnames(train_dt_va)[13]="seq"

#Creating an empty data frame for validation sub-data set with required columns names
validation_dt <- data.frame(matrix(ncol = 13, nrow = 0))
# Set columns names  for validation data set 
colnames(validation_dt) <- colnames(sap.train)
#Adding seq column to validation data set
colnames(validation_dt)[13]="seq"
 
# Creating the validation data  based on the brands list
for(i in 1:length(levels)){
  
 #Subset based on the brand list index i
 df_brand <- subset(testing_dt ,Brand== levels[i] )

 df_brand$seq <- 1:nrow(df_brand)

# Get 80% as sub-training data
 gl_data_train <- df_brand %>% dplyr::sample_frac(0.80)
 
 # Combining the sub-training datasets
 train_dt_va <-rbind(train_dt_va, gl_data_train)

 # Get the 20% as sub-validation data
 gl_data_test  <- dplyr::anti_join(df_brand, gl_data_train , by = 'seq')
 
 # Combining the sub-validation datasets
 validation_dt <-rbind(validation_dt, gl_data_test)
}

#Removing seq variable from training, validation and test datasets
validation_dt <- validation_dt [,-12]

# Checking the data 

dim(validation_dt)

```

The validation data is a subset of test data and has 2393 records.

**Ref:**

-   Z. (2022, April 12). How to Split Data into Training & Test Sets in R. Statology. Retrieved March 11, 2023, from <https://www.statology.org/train-test-split-r/>
-   R: How to split a data frame into training, validation, and test sets?, Stack Overflow. Retrieved March 11, 2023, from <https://stackoverflow.com/questions/36068963/r-how-to-split-a-data-frame-into-training-validation-and-test-sets>.

#### Step 5: Creating the Model to Predict Brands

#### Approach taken : Since the response variable has more than two classes and collinearity in the predictor variables, we chose LDA for variable selection based on the best accuracy observed. Since the predictors have lot of similar characters, we took a approach to add variable interactions and transformations to LDA model to increase the accuracy and find the best model. We tested three LDA model with different scenarios.

a: Variable selection using the box plots and testing accuracy of LDA models with different predictors

```{r}
set.seed(1234)
# Removing the shape from the training dataset 

brand_df <- training_dt[,c(-1,-3)]

#Fitting the LDA Model with Brand as the response variable and using all the Predictors.
Brand_LDA_MDL1 = lda(Brand ~ . , data=brand_df)

# Testing the model on validation set
Brand_LDA_pred1 <-predict(Brand_LDA_MDL1,validation_dt)

# Get the response variable values,model predictions
Brand_LDA_Predictions1 <- Brand_LDA_pred1$class

# Get the actual response variable values from testing data
true_values <- validation_dt$Brand

# Get Accuracy Matrix
# table(Brand_LDA_Predictions1, true_values)

# Calculating the accuracy
Brand_LDA_mdl1_Accr <- mean(Brand_LDA_Predictions1 ==true_values)

#Getting the accuracy by each Brand 
#Count of True Values by each Brand

True_values1 <- validation_dt %>% 
                group_by(Brand) %>%
                summarise(True_value=n())

# True Predicted values 
validation_dt1 <- validation_dt
validation_dt1$Brand_LDA_Predictions1 <- Brand_LDA_pred1$class

Predicted_value_data1 <- validation_dt1 %>% filter(Brand == Brand_LDA_Predictions1) 

#Count of Predicted Values by each Brand

Predicted_values1 <- Predicted_value_data1 %>% 
                    group_by(Brand_LDA_Predictions1) %>%
                    summarise(Predicted_value=n())

colnames(Predicted_values1)[1] <- "Brand"

#Merging the True Value data by Predicted Values

Accuracy1 <- data.frame(merge(x= True_values1, y=Predicted_values1,by="Brand", all.x=TRUE))

# Calculating the Accuracy by Each Brand 

Accuracy1$accuracy_percent <- Accuracy1$Predicted_value/ Accuracy1$True_value

# Dropping the variables for final accuracy data set 
AllBrand_LDA_mdl1_Accr = subset(Accuracy1 , select = c(Brand,accuracy_percent))

# Accuracy by each brand 

#AllBrand_LDA_mdl1_Accr

# Showing the count of brands where the accuracy is above then or equal to 80% 
AllBrand_LDA_mdl1_Accr_Up <- AllBrand_LDA_mdl1_Accr[!is.na(AllBrand_LDA_mdl1_Accr$accuracy_percent), ]
AllBrand_LDA_mdl1_Accr_Up <- AllBrand_LDA_mdl1_Accr_Up %>% filter(accuracy_percent >= .80) 
AllBrand_LDA_mdl1_Accr_Up <- AllBrand_LDA_mdl1_Accr_Up %>% 
                            summarise(Accuracy_Above_80=n())
AllBrand_LDA_mdl1_Accr_Up

# Counting the  number of brands with absolute mis-classification ( 100 percent mis-classification).
AllBrand_LDA_mdl1_Accr_mis<- AllBrand_LDA_mdl1_Accr[is.na(AllBrand_LDA_mdl1_Accr$accuracy_percent), ]
AllBrand_LDA_mdl1_Accr_mis <- AllBrand_LDA_mdl1_Accr_mis %>% 
                            summarise(Missing_pred=n())
AllBrand_LDA_mdl1_Accr_mis

#Overall LDA Model 1 Accuracy Printing Results
cat("LDA Accuracy mdl1 for Brand is:", Brand_LDA_mdl1_Accr)

```

#### b: LDA Model2 with Brand as the response variables and log(Area) + log(Perim.) + log(Major) + Minor + Circ. + AR + Round + Solidity + Area \* Perim. \* Major + Solidity \* Circ. \* Round predictors.

```{r}

set.seed(1234)

#Fitting the LDA Model with Brand as the response variable and log(Area) + log(Perim.) + log(Major) + Minor + Circ. + AR + Round + Solidity + Area \* Perim. \* Major + Solidity \* Circ. \* Round  predictors.
Brand_LDA_MDL2 = lda(Brand ~ log(Area) + log(Perim.) + log(Major) + Minor + Circ. + AR + Round + Solidity +  Area * Perim. * Major +  Solidity * Circ. * Round , data=brand_df)

# Testing the model on validation set
Brand_LDA_pred2 <-predict(Brand_LDA_MDL2,validation_dt)

# Get the response variable values,model predictions
Brand_LDA_Predictions2 <- Brand_LDA_pred2$class

# Get Accuracy Matrix
# table(Brand_LDA_Predictions2, true_values)

# Calculating the accuracy
Brand_LDA_mdl2_Accr <- mean(Brand_LDA_Predictions2 ==true_values)

#Getting the accuracy by each Brand 
#Count of True Values by each Brand

True_values2 <- validation_dt %>% 
               group_by(Brand) %>%
               summarise(True_value=n())

# True Predicted values 
validation_dt2 <- validation_dt
validation_dt2$Brand_LDA_Predictions2 <- Brand_LDA_pred2$class

Predicted_value_data2 <- validation_dt2 %>% filter(Brand == Brand_LDA_Predictions2) 

#Count of Predicted Values by each Brand

Predicted_values2 <- Predicted_value_data2 %>% 
                    group_by(Brand_LDA_Predictions2) %>%
                    summarise(Predicted_value=n())

colnames(Predicted_values2)[1] <- "Brand"

#Merging the True Value data by Predicted Values

Accuracy2 <- data.frame(merge(x=True_values2,y= Predicted_values2,by="Brand", all.x=TRUE))

# Calculating the Accuracy by Each Brand 

Accuracy2$accuracy_percent <- Accuracy2$Predicted_value/ Accuracy2$True_value

# Dropping the variables for final accuracy data set 
AllBrand_LDA_mdl2_Accr = subset(Accuracy2 , select = c(Brand,accuracy_percent))

# Accuracy by each brand 

#AllBrand_LDA_mdl2_Accr

# Showing the count of brands where the accuracy is above then or equal to 80% 
AllBrand_LDA_mdl2_Accr_Up <- AllBrand_LDA_mdl2_Accr[!is.na(AllBrand_LDA_mdl2_Accr$accuracy_percent), ]
AllBrand_LDA_mdl2_Accr_Up <- AllBrand_LDA_mdl2_Accr_Up %>% filter(accuracy_percent >= .80) 
AllBrand_LDA_mdl2_Accr_Up <- AllBrand_LDA_mdl2_Accr_Up %>% 
                            summarise(Accuracy_Above_80=n())
AllBrand_LDA_mdl2_Accr_Up

# Counting the number of brands with absolute mis-classification ( 100 percent mis-classification).
AllBrand_LDA_mdl2_Accr_mis<- AllBrand_LDA_mdl2_Accr[is.na(AllBrand_LDA_mdl2_Accr$accuracy_percent), ]
AllBrand_LDA_mdl2_Accr_mis <- AllBrand_LDA_mdl2_Accr_mis %>% 
                            summarise(Missing_pred=n())
AllBrand_LDA_mdl2_Accr_mis

#Overall LDA Model 2 Accuracy Printing Results
cat("LDA Accuracy mdl2 for Brand is:", Brand_LDA_mdl2_Accr)

```

#### c: LDA Model3 with Shape as the response variables and log(Area) + log(Perim.) + Major + Minor + Circ. + AR + Round + Solidity + Area \* Major \* Circ. + Perim. \* Major \* Solidity predictors..

```{r}
set.seed(1234)

#Fitting the LDA Model with Brand as the response variable and log(Area) + log(Perim.) + Major + Minor + Circ. + AR + Round + Solidity + Area \* Major \* Circ. + Perim. \* Major \* Solidity predictors.
Brand_LDA_MDL3 = lda(Brand ~ log(Area) + log(Perim.) + Major + Minor + Circ. + AR + Round + Solidity +  Area *  Major * Circ. + Perim. * Major * Solidity, data=brand_df)

# Testing the model on validation set
Brand_LDA_pred3 <-predict(Brand_LDA_MDL3,validation_dt)

# Get the response variable values,model predictions
Brand_LDA_Predictions3 <- Brand_LDA_pred3$class

# Get Accuracy Matrix
# table(Brand_LDA_Predictions3, true_values)

# Calculating the accuracy
Brand_LDA_mdl3_Accr <- mean(Brand_LDA_Predictions3 ==true_values)

#Getting the accuracy by each Brand 
#Count of True Values by each Brand

True_values3 <- validation_dt %>% 
               group_by(Brand) %>%
               summarise(True_value=n())

# True Predicted values 
validation_dt3 <- validation_dt
validation_dt3$Brand_LDA_Predictions3 <- Brand_LDA_pred3$class

Predicted_value_data3 <- validation_dt3 %>% filter(Brand == Brand_LDA_Predictions3) 

#Count of Predicted Values by each Brand

Predicted_values3 <- Predicted_value_data3 %>% 
                    group_by(Brand_LDA_Predictions3) %>%
                    summarise(Predicted_value=n())

colnames(Predicted_values3)[1] <- "Brand"

#Merging the True Value data by Predicted Values

Accuracy3 <- data.frame(merge(x=True_values3,y= Predicted_values3,by="Brand", all.x=TRUE))

# Calculating the Accuracy by Each Brand 

Accuracy3$accuracy_percent <- Accuracy3$Predicted_value/ Accuracy3$True_value

# Dropping the variables for final accuracy data set 
AllBrand_LDA_mdl3_Accr = subset(Accuracy3 , select = c(Brand,accuracy_percent))

# Accuracy by each brand 

#AllBrand_LDA_mdl3_Accr

# Showing the count of brands where the accuracy is above then or equal to 80% 
AllBrand_LDA_mdl3_Accr_Up <- AllBrand_LDA_mdl3_Accr[!is.na(AllBrand_LDA_mdl3_Accr$accuracy_percent), ]
AllBrand_LDA_mdl3_Accr_Up <- AllBrand_LDA_mdl3_Accr_Up %>% filter(accuracy_percent >= .80) 
AllBrand_LDA_mdl3_Accr_Up <- AllBrand_LDA_mdl3_Accr_Up %>% 
                            summarise(Accuracy_Above_80=n())
AllBrand_LDA_mdl3_Accr_Up

# Counting the number of brands with absolute mis-classification ( 100 percent mis-classification).
AllBrand_LDA_mdl3_Accr_mis<- AllBrand_LDA_mdl3_Accr[is.na(AllBrand_LDA_mdl3_Accr$accuracy_percent), ]
AllBrand_LDA_mdl3_Accr_mis <- AllBrand_LDA_mdl3_Accr_mis %>% 
                            summarise(Missing_pred=n())
AllBrand_LDA_mdl3_Accr_mis

#Overall LDA Model 3 Accuracy Printing Results
cat("LDA Accuracy mdl3 for Brand is:", Brand_LDA_mdl3_Accr)

```

From the above LDA model: LDA model2 has an overall accuracy of 29 percent. It predicted 9 brands with an accuracy above 80 percent. It classified 52% of the unique brands, but has 48% absolute mis-classification, in comparison to other LDA models the absolute mis-classification is the least for LDA model2.

**Ref**:

-   Z. (2020, October 30). Linear Discriminant Analysis in R (Step-by-Step). Statology. Retrieved March 11, 2023, from <https://www.statology.org/linear-discriminant-analysis-in-r/>
-   Sarkar, Priyankur. "What Is LDA: Linear Discriminant Analysis for Machine Learning." What Is Linear Discriminant Analysis (LDA)?, Knowledgehut, 27 Dec. 2022, <https://www.knowledgehut.com/blog/data-science/linear-discriminant-analysis-for-machine-learning>.

#### Step 6: Beginning QDA Analysis with Brand as the response variables and log(Area) + log(Perim.) + log(Major) + Minor + Circ. + AR + Round + Solidity + Area \* Perim. \* Major + Solidity \* Circ. \* Round predictors..

#### QDA model

```{r}
set.seed(1234)

#Fitting the QDA Model with Brand as the response variable and using log(Area) + log(Perim.) + log(Major) + Minor + Circ. + AR + Round + Solidity +  Area * Perim. * Major +  Solidity * Circ. * Round predictors. 
Brand_QDA_MDL = qda(Brand ~ log(Area) + log(Perim.) + log(Major) + Minor + Circ. + AR + Round + Solidity +  Area * Perim. * Major +  Solidity * Circ. * Round , data=brand_df)

# Testing the model on validation set
Brand_QDA_pred <-predict(Brand_QDA_MDL,validation_dt)

# Get the response variable values,model predictions
Brand_QDA_Predictions <- Brand_QDA_pred$class

# Get Accuracy Matrix
# table(Brand_QDA_Predictions, true_values)

# Calculating the accuracy
Brand_QDA_mdl_Accr <- mean(Brand_QDA_Predictions ==true_values)

#Getting the accuracy by each Brand 
#Count of True Values by each Brand

QDA_True_values <- validation_dt %>% 
               group_by(Brand) %>%
               summarise(True_value=n())

# True Predicted values 
QDA_validation_dt <- validation_dt
QDA_validation_dt$Brand_QDA_Predictions <- Brand_QDA_pred$class

QDA_Predicted_value_data <- QDA_validation_dt %>% filter(Brand == Brand_QDA_Predictions) 

#Count of Predicted Values by each Brand

QDA_Predicted_values <- QDA_Predicted_value_data %>% 
                    group_by(Brand_QDA_Predictions) %>%
                    summarise(Predicted_value=n())

colnames(QDA_Predicted_values)[1] <- "Brand"

#Merging the True Value data by Predicted Values

QDA_Accuracy <- data.frame(merge(x=QDA_True_values,y= QDA_Predicted_values,by="Brand", all.x=TRUE))

# Calculating the Accuracy by Each Brand 

QDA_Accuracy$accuracy_percent <- QDA_Accuracy$Predicted_value/ QDA_Accuracy$True_value

# Dropping the variables for final accuracy data set 
AllBrand_QDA_mdl_Accr = subset(QDA_Accuracy , select = c(Brand,accuracy_percent))

# Accuracy by each brand 

#AllBrand_QDA_mdl_Accr

# Showing the count of brands where the accuracy is above then or equal to 80% 
AllBrand_QDA_mdl_Accr_Up <- AllBrand_QDA_mdl_Accr[!is.na(AllBrand_QDA_mdl_Accr$accuracy_percent), ]
AllBrand_QDA_mdl_Accr_Up <- AllBrand_QDA_mdl_Accr_Up %>% filter(accuracy_percent >= .80) 
AllBrand_QDA_mdl_Accr_Up <- AllBrand_QDA_mdl_Accr_Up %>% 
                            summarise(Accuracy_Above_80=n())
AllBrand_QDA_mdl_Accr_Up

# Counting the number of brands with absolute mis-classification ( 100 percent mis-classification).
AllBrand_QDA_mdl_Accr_mis<- AllBrand_QDA_mdl_Accr[is.na(AllBrand_QDA_mdl_Accr$accuracy_percent), ]
AllBrand_QDA_mdl_Accr_mis <- AllBrand_QDA_mdl_Accr_mis %>% 
                            summarise(Missing_pred=n())
AllBrand_QDA_mdl_Accr_mis

#Overall QDA Model  Accuracy Printing Results
cat("QDA Accuracy mdl for Brand is:", Brand_QDA_mdl_Accr)


```

From the above QDA model: QDA model has an overall accuracy of 22 percent. It predicted 19 brands with an accuracy above 80 percent which is better than the LDA model. It classified 49 % of the unique brands, but has 51% absolute mis-classification, in comparison to the LDA model the absolute mis-classification is higher.

**Ref:**

-   Z. (2020, November 2). Quadratic Discriminant Analysis in R (Step-by-Step). Statology. Retrieved March 12, 2023, from <https://www.statology.org/quadratic-discriminant-analysis-in-r/>
-   Saunders, C. (2023, February 10). Classification Part 2 LDA and QDA [Lecture]. D2l.Sdbor.edu. <https://d2l.sdbor.edu/d2l/le/content/1781558/viewContent/11116132/View>

#### Step 7: Beginning Random forest with Brand as the response variables and log(Area) + log(Perim.) + log(Major) + Circ. + AR + Round + Solidity + Area \* Major \* Circ. + Perim. \* Major \* Round interactions.

```{r}
set.seed(1234)

#Fitting the randomForest
Brand_randomForest_MDL = randomForest(Brand ~ log(Area) + log(Perim.) + log(Major)  + Circ. + AR + Round + Solidity +  Area * Major * Circ. + Perim. * Major * Round  , data=brand_df)

# Testing the model on validation set
Brand_randomForest_Predictions  <-predict(Brand_randomForest_MDL,validation_dt)

# Get Accuracy Matrix
# table(Brand_randomForest_Predictions, true_values)

# Calculating the accuracy
Brand_randomForest_mdl_Accr <- mean(Brand_randomForest_Predictions ==true_values)

#Getting the accuracy by each Brand 
#Count of True Values by each Brand

randomForest_True_values <- validation_dt %>% 
               group_by(Brand) %>%
               summarise(True_value=n())

# True Predicted values 
randomForest_validation_dt <- validation_dt
randomForest_validation_dt$Brand_randomForest_Predictions <- predict(Brand_randomForest_MDL,validation_dt)

randomForest_Predicted_value_data <- randomForest_validation_dt %>% filter(Brand == Brand_randomForest_Predictions) 

#Count of Predicted Values by each Brand

randomForest_Predicted_values <- randomForest_Predicted_value_data %>% 
                    group_by(Brand_randomForest_Predictions) %>%
                    summarise(Predicted_value=n())

colnames(randomForest_Predicted_values)[1] <- "Brand"

#Merging the True Value data by Predicted Values

randomForest_Accuracy <- data.frame(merge(x=randomForest_True_values,y= randomForest_Predicted_values,by="Brand", all.x=TRUE))

# Calculating the Accuracy by Each Brand 

randomForest_Accuracy$accuracy_percent <- randomForest_Accuracy$Predicted_value/ randomForest_Accuracy$True_value

# Dropping the variables for final accuracy data set 
AllBrand_randomForest_mdl_Accr = subset(randomForest_Accuracy , select = c(Brand,accuracy_percent))

# Accuracy by each brand 

#AllBrand_randomForest_mdl_Accr

# Showing the count of brands where the accuracy is above then or equal to 80% 
AllBrand_randomForest_mdl_Accr_Up <- AllBrand_randomForest_mdl_Accr[!is.na(AllBrand_randomForest_mdl_Accr$accuracy_percent), ]
AllBrand_randomForest_mdl_Accr_Up <- AllBrand_randomForest_mdl_Accr_Up %>% filter(accuracy_percent >= .80) 
AllBrand_randomForest_mdl_Accr_Up <- AllBrand_randomForest_mdl_Accr_Up %>% 
                            summarise(Accuracy_Above_80=n())
AllBrand_randomForest_mdl_Accr_Up 

# Counting the number of brands with absolute mis-classification (100 percent mis-classification).
AllBrand_randomForest_mdl_Accr_mis<- AllBrand_randomForest_mdl_Accr[is.na(AllBrand_randomForest_mdl_Accr$accuracy_percent), ]
AllBrand_randomForest_mdl_Accr_mis <- AllBrand_randomForest_mdl_Accr_mis %>% 
                            summarise(Missing_pred=n())
AllBrand_randomForest_mdl_Accr_mis

#Overall Random Forest Model  Accuracy Printing Results
cat("Random Forest Accuracy mdl for Brand is:", Brand_randomForest_mdl_Accr)

```

From the above Random Forest model: Random Forest model has an overall accuracy of 32 percent. It predicted 9 brands with an accuracy above 80 percent, which is very close to LDA and QDA models. It classified 74% of the unique brands, but have 26% absolute mis-classification, in comparison to other models the absolute mis-classification is the least for Randomforest model.

**Ref:**

-   Finnstats. (2021, April 13). Random Forest in R: R-bloggers. R. Retrieved April 22, 2023, from <https://www.r-bloggers.com/2021/04/random-forest-in-r/>

#### Step 8: Beginning MclustDa model with Brand as the response variable.

```{r}

'Set seed'
set.seed(123)

#separate the predictors we will be using in the model
mclustTrain <- brand_df[ , c("Area","Perim.","Major","Circ.", "AR","Round","Solidity")] 
mclustTest <- validation_dt[ , c("Area","Perim.","Major","Circ.", "AR","Round","Solidity")] 

#separate the Brand variable from the training data
mclustClass <- brand_df[ , c("Brand")]

# Fitting the MclustDA Model using Eccentricity, Extent & Area Predictors with G= 1
mclust.mod <- MclustDA(mclustTrain, mclustClass, G = 1)

#Print summary
#summary(mclust.mod)

# Predictions on test data

MclustDA_pred <- predict.MclustDA(mclust.mod, newdata = mclustTest)

MclustDA_predictions <- MclustDA_pred$class

true_values <- validation_dt$Brand

# Confusion Matrix of MclustDA model
# table(MclustDA_predictions, validation_dt$Brand)

# Finding accuracy of MclustDA model

Brand_MclustDA_Accr<- mean(MclustDA_predictions==validation_dt$Brand)

#Getting the accuracy by each Brand 
#Count of True Values by each Brand

MclustDA_True_values <- validation_dt %>% 
               group_by(Brand) %>%
               summarise(True_value=n())

# True Predicted values 
MclustDA_validation_dt <- validation_dt
MclustDA_validation_dt$Brand_MclustDA_Predictions <- MclustDA_predictions

MclustDA_Predicted_value_data <- MclustDA_validation_dt %>% filter(Brand == Brand_MclustDA_Predictions) 

#Count of Predicted Values by each Brand

MclustDA_Predicted_values <- MclustDA_Predicted_value_data %>% 
                    group_by(Brand_MclustDA_Predictions) %>%
                    summarise(Predicted_value=n())

colnames(MclustDA_Predicted_values)[1] <- "Brand"

#Merging the True Value data by Predicted Values

MclustDA_Accuracy <- data.frame(merge(x=MclustDA_True_values,y= MclustDA_Predicted_values,by="Brand", all.x=TRUE))

# Calculating the Accuracy by Each Brand 

MclustDA_Accuracy$accuracy_percent <- MclustDA_Accuracy$Predicted_value/ MclustDA_Accuracy$True_value

# Dropping the variables for final accuracy data set 
AllBrand_MclustDA_mdl_Accr = subset(MclustDA_Accuracy , select = c(Brand,accuracy_percent))

# Accuracy by each brand 

#AllBrand_MclustDA_mdl_Accr

# Showing the count of brands where the accuracy is above then or equal to 80% 
AllBrand_MclustDA_mdl_Accr_Up <- AllBrand_MclustDA_mdl_Accr[!is.na(AllBrand_MclustDA_mdl_Accr$accuracy_percent), ]
AllBrand_MclustDA_mdl_Accr_Up <- AllBrand_MclustDA_mdl_Accr_Up %>% filter(accuracy_percent >= .80) 
AllBrand_MclustDA_mdl_Accr_Up <- AllBrand_MclustDA_mdl_Accr_Up %>% 
                            summarise(Accuracy_Above_80=n())
AllBrand_MclustDA_mdl_Accr_Up 

# Counting the number of brands with absolute mis-classification (100 percent mis-classification).
AllBrand_MclustDA_mdl_Accr_mis<- AllBrand_MclustDA_mdl_Accr[is.na(AllBrand_MclustDA_mdl_Accr$accuracy_percent), ]
AllBrand_MclustDA_mdl_Accr_mis <- AllBrand_MclustDA_mdl_Accr_mis %>% 
                            summarise(Missing_pred=n())
AllBrand_MclustDA_mdl_Accr_mis

#Overall MclustDA Model  Accuracy Printing Results
cat("MclustDAAccuracy mdl for Brand is:", Brand_MclustDA_Accr)

```

From the above MclustDA model: MclustDA model has an overall accuracy of 24 percent. It predicted 16 brands with an accuracy above 80 percent. It classified 45% of the unique brands, but has 55% absolute mis-classification, in comparison to Randomforest model the mis-classification is high.

**Ref:**

-   Fraley, C., Raftery, A. E., & Scrucca, L. (n.d.). MclustDA discriminant analysis. Mclust-Org.Github. Retrieved March 13, 2023, from <https://mclust-org.github.io/mclust/reference/MclustDA.html>

-   [shanem\@mtu.edu](mailto:shanem@mtu.edu){.email}, Shane T. Mueller. Model-Based Clustering and Mclust, 28 Mar. 2021, <https://pages.mtu.edu/~shanem/psy5220/daily/Day19/modelbasedclustering.html#content>.

-   Saunders, C. (2023, February 24). MclustDA part1 [Lecture]. D2l.Sdbor.edu. <https://d2l.sdbor.edu/d2l/le/content/1781558/viewContent/11116023/View>

-   Saunders, C. (2023, February 24). MclustDA part2 [Lecture]. D2l.Sdbor.edu. <https://d2l.sdbor.edu/d2l/le/content/1781558/viewContent/11116022/View>

-   Saunders, C. (2023, February 24). MclustDA part3 Cross validation [Lecture]. D2l.Sdbor.edu. <https://d2l.sdbor.edu/d2l/le/content/1781558/viewContent/11116024/View>

-   Saunders, C. (2023, February 24). Mclust Play Part2 R file [Lecture]. D2l.Sdbor.edu. <https://d2l.sdbor.edu/d2l/le/content/1781558/viewContent/11116026/View>

-   Saunders, C. (2023, February 24). Mclust Play Part3 R file [Lecture]. D2l.Sdbor.edu. <https://d2l.sdbor.edu/d2l/le/content/1781558/viewContent/11116025/View>

#### Step 9: Creating table for final prediction:

#### Smokeless Gun Powder data results in the form of a table

```{r}

# Creating a Table for the final results from all the models

Test_Model_Metrics <- data.frame(cbind(Models = c("LDA", "QDA", "Randomforest", "MclustDA"),
                                       Overall_Accuracy           = round(c(Brand_LDA_mdl2_Accr, Brand_QDA_mdl_Accr, Brand_randomForest_mdl_Accr, Brand_MclustDA_Accr),4),
                                       Brand_Count_with_Acc_80    = (c(AllBrand_LDA_mdl2_Accr_Up$Accuracy_Above_80 , AllBrand_QDA_mdl_Accr_Up$Accuracy_Above_80 , AllBrand_randomForest_mdl_Accr_Up$Accuracy_Above_80 , AllBrand_MclustDA_mdl_Accr_Up$Accuracy_Above_80)),
                                       Brand_Count_with_Pred_Mis  = (c(AllBrand_LDA_mdl2_Accr_mis$Missing_pred, AllBrand_QDA_mdl_Accr_mis$Missing_pred, AllBrand_randomForest_mdl_Accr_mis$Missing_pred, AllBrand_MclustDA_mdl_Accr_mis$Missing_pred))))
                                       
kable(Test_Model_Metrics , caption = "Model Results Analysis Table")

```

Based on the above table we can see that Random Forest has the best overall accuracy of 32%. It predicted 9 brands with an accuracy above 80 percent, which is very close to LDA and QDA models. It classified 74% of the unique brands, but have 26% absolute mis-classification, in comparison to other models the absolute mis-classification is the least for the Randomforest model. This is the best model for the analysis.

**Ref:**

-   kTable: Make Nicely Formatted Tables in Kmisc: Kevin Miscellaneous. (n.d.). Rdrr.io. Retrieved April 25, 2023, from <https://rdrr.io/cran/Kmisc/man/kTable.html>

#### Step 10: Creating table for final prediction by each model

```{r, warning=FALSE}
# Creating a Table for the final accuracy by each model. 

Accuracy_b <- data.frame(merge(x=AllBrand_LDA_mdl2_Accr,y= AllBrand_QDA_mdl_Accr,by="Brand", all.x=TRUE))
Accuracy_c <- data.frame(merge(x=Accuracy_b,y= AllBrand_randomForest_mdl_Accr,by="Brand", all.x=TRUE))
Accuracy_by_Brand <- data.frame(merge(x=Accuracy_c,y= AllBrand_MclustDA_mdl_Accr,by="Brand", all.x=TRUE))
colnames(Accuracy_by_Brand)[2] <- "LDA_accuracy_percent"
colnames(Accuracy_by_Brand)[3] <- "QDA_accuracy_percent"
colnames(Accuracy_by_Brand)[4] <- "RandomForest_accuracy_percent"
colnames(Accuracy_by_Brand)[5] <- "MclustDAt_accuracy_percent"

# Showing the best accuracy by brands for random forest and checking how other models did for the same brands
Accuracy_by_Brand_Up <-  Accuracy_by_Brand[!is.na(Accuracy_by_Brand$RandomForest_accuracy_percent), ]
Top_10_Accuracy<- Accuracy_by_Brand_Up[order(Accuracy_by_Brand_Up$RandomForest_accuracy_percent),]
Top_10_Accuracy <- tail(Top_10_Accuracy, n=10)
Top_10_Accuracy
```

#### Step 11a: Summary and importance of the Random forest Model.

```{r}
# Summary of the selected random forest model
summary(Brand_randomForest_MDL)

# Importance of the variables in selected Random forest model. 
importance(Brand_randomForest_MDL) 

# Plotting Random forest Variable Importance. 
varImpPlot(Brand_randomForest_MDL,main = "Variable Importance in Selected Random Forest Model")
```

#### Step 11b: Testing the Random forest Model.

```{r}
set.seed(1234)

# Testing the model on test set
Brand_randomForest_Predictions1  <-predict(Brand_randomForest_MDL,testing_dt)

# Get Accuracy Matrix
#table(Brand_randomForest_Predictions1, testing_dt$Brand)

# Calculating the accuracy
Brand_randomForest_mdl_Accr1 <- mean(Brand_randomForest_Predictions1 ==testing_dt$Brand)

#Getting the accuracy by each Brand 
#Count of True Values by each Brand

randomForest_True_values <- testing_dt %>% 
               group_by(Brand) %>%
               summarise(True_value=n())

# True Predicted values 
randomForest_testing_dt1 <- testing_dt
randomForest_testing_dt1$Brand_randomForest_Predictions1 <- predict(Brand_randomForest_MDL,testing_dt)

randomForest_Predicted_value_data1 <- randomForest_testing_dt1 %>% filter(Brand == Brand_randomForest_Predictions1) 

#Count of Predicted Values by each Brand

randomForest_Predicted_values1 <- randomForest_Predicted_value_data1 %>% 
                    group_by(Brand_randomForest_Predictions1) %>%
                    summarise(Predicted_value=n())

colnames(randomForest_Predicted_values1)[1] <- "Brand"

#Merging the True Value data by Predicted Values

randomForest_Accuracy1 <- data.frame(merge(x=randomForest_True_values,y= randomForest_Predicted_values1,by="Brand", all.x=TRUE))

# Calculating the Accuracy by Each Brand 

randomForest_Accuracy1$accuracy_percent <- randomForest_Accuracy1$Predicted_value/ randomForest_Accuracy1$True_value

# Dropping the variables for final accuracy data set 
AllBrand_randomForest_mdl_Accr1 = subset(randomForest_Accuracy1 , select = c(Brand,accuracy_percent))

# Accuracy by each brand 

AllBrand_randomForest_mdl_Accr1

#Overall randomForestinal Model  Accuracy Printing Results
cat("randomForest Accuracy mdl for Brand is:", Brand_randomForest_mdl_Accr1)

```

The Final testing confirms that the random forest is the best model for predicting the Brand.

#### Step 12: Creating a Model to predict the Shape. We are creating this to validate our results based on the Shape.

```{r}
# Creating a Train data for Shape

Shape_df <- training_dt[,c(-1,-2)]

set.seed(1234)

# Fitting the randomforest Model using shape as the response variable and  log(Area) + log(Perim.) + log(Major)  + Circ. + AR + Round + Solidity +  Area * Major * Circ. + Perim. * Major * Round predictors. 
Shape_randomforest_MDL = randomForest(Shape~ log(Area) + log(Perim.) + log(Major)  + Circ. + AR + Round + Solidity +  Area * Major * Circ. + Perim. * Major * Round, data=Shape_df)

# Testing the model
Shape_randomforest_Predictions <-predict(Shape_randomforest_MDL,testing_dt)

# Get the actual response variable values from testing data
true_values <- testing_dt$Shape

# Get Accuracy Matrix
#table(Shape_randomforest_Predictions, true_values)

# Calculating the accuracy
Shape_randomforest_mdl_Accr <- mean(Shape_randomforest_Predictions  ==true_values)

# Printing Results
cat("Randomforest Accuracy for Shape is:",Shape_randomforest_mdl_Accr)
```

The Overall Accuracy for shape is 90%.

#### Step 13: Prediction of Recovered Samples using the RandomForest Model.

#### Part1: Sample 1 and Sample 2 Analysis (Comparing the brands and finding the brand name).

#### Predictions of recovered sample 1

```{r}
set.seed(1234)
# Predicting Sample 1 using the Random forest Model 
recovered.sample1$Brand <-predict(Brand_randomForest_MDL,recovered.sample1)

# final Predictions: 

sample1_Pred <- data.frame(merge(recovered.sample1,AllBrand_randomForest_mdl_Accr1,by="Brand"))

sample1_values <- sample1_Pred %>% 
      group_by(Brand) %>%
      summarise(Predicted_value=sum(accuracy_percent))

# Finding the brand 
Brand.Sample1 <- sample1_values[order(sample1_values$Predicted_value),]
Brand.Sample1<- tail(Brand.Sample1, n=1)
Brand.Sample1

# Testing the other models to confirm our results
red.Dot.accr<- Accuracy_by_Brand %>% 
  filter(Accuracy_by_Brand$Brand == "RedDot")
#red.Dot.accr

#Implementing LDA
# Predicting Sample 1 using the Random forest Model 
LDA_sample1<-predict(Brand_LDA_MDL2,recovered.sample1)

Lda_sample1_N <- data.frame(LDA_sample1$class)

LDA_sample.1 <- Lda_sample1_N %>% 
      group_by(LDA_sample1.class) %>%
      summarise(Predicted_value=n())

# Finding the brand using LDA
LDA_Brand.Sample1 <- LDA_sample.1[order(LDA_sample.1$Predicted_value),]
LDA_Brand.Sample1<- tail(LDA_Brand.Sample1, n=1)
LDA_Brand.Sample1

#Implementing Random Forest for Shape 

# Predicting Sample 1 using the Random forest Model 
randomforest_Shape_sample1 <- data.frame(predict(Shape_randomforest_MDL,recovered.sample1))

randomforest_Shape_sample1_values <- randomforest_Shape_sample1 %>% 
      group_by(predict.Shape_randomforest_MDL..recovered.sample1.) %>%
      summarise(Predicted_value=n())

randomforest_Shape_sample1_values<- randomforest_Shape_sample1_values[order(randomforest_Shape_sample1_values$Predicted_value),]
randomforest_Shape_sample1_values<- tail(randomforest_Shape_sample1_values, n=1)
randomforest_Shape_sample1_values

```

Based on the results from the selected Random Forest model recovered sample 1 has the highest predicted value of 164 and is from Brand Reddot. We validated our results by implementing the LDA Model and the predicted value of Reddot is the highest with LDA as well. To further confirm our results, we predicted the shape of the recovered sample 1 and the flake has the highest predicted value. We checked the shape of Reddot is Flake from the train data, this confirms our results that the recovered sample 1 is from the brand Reddot.

#### Predictions of recovered sample 2

```{r}
set.seed(1234)
# Predicting Sample 2 using the Random forest Model 
recovered.sample2$Brand <-predict(Brand_randomForest_MDL,recovered.sample2)

# final Predictions: 

sample2_Pred <- data.frame(merge(recovered.sample2,AllBrand_randomForest_mdl_Accr1,by="Brand"))

sample2_values <- sample2_Pred %>% 
      group_by(Brand) %>%
      summarise(Predicted_value=sum(accuracy_percent))

# Finding the brand 
Brand.Sample2 <- sample2_values[order(sample2_values$Predicted_value),]
Brand.Sample2<- tail(Brand.Sample2, n=1)
Brand.Sample2

# Testing the other models to confirm our results
red.Dot.accr<- Accuracy_by_Brand %>% 
  filter(Accuracy_by_Brand$Brand == "RedDot")
#red.Dot.accr

#Implementing LDA
# Predicting Sample 2 using the Random forest Model 
LDA_sample2<-predict(Brand_LDA_MDL2,recovered.sample2)

Lda_sample2_N <- data.frame(LDA_sample2$class)

LDA_sample.2 <- Lda_sample2_N %>% 
      group_by(LDA_sample2.class) %>%
      summarise(Predicted_value=n())

# Finding the brand 
LDA_Brand.Sample2 <- LDA_sample.2[order(LDA_sample.2$Predicted_value),]
LDA_Brand.Sample2<- tail(LDA_Brand.Sample2, n=1)
LDA_Brand.Sample2

#Implementing Random Forest for Shape 

# Predicting Sample 2 using the Random forest Model 
randomforest_Shape_sample2 <- data.frame(predict(Shape_randomforest_MDL,recovered.sample2))

randomforest_Shape_sample2_values <- randomforest_Shape_sample2 %>% 
      group_by(predict.Shape_randomforest_MDL..recovered.sample2.) %>%
      summarise(Predicted_value=n())

randomforest_Shape_sample2_values<- randomforest_Shape_sample2_values[order(randomforest_Shape_sample2_values$Predicted_value),]
randomforest_Shape_sample2_values<- tail(randomforest_Shape_sample2_values, n=1)
randomforest_Shape_sample2_values



```

Based on the results from the selected Random Forest model recovered sample 2 has the highest predicted value of 65 and is from Brand Reddot. We validated our results by implementing the LDA Model and the predicted value of Reddot is the highest with LDA as well. To further confirm our results, we predicted the shape of the recovered sample 2 and the flake has the highest predicted value. This confirms our results that the recovered sample 2 is from the brand Reddot.

#### Part 2: Smokeless Gun Powder presence of multiple Brand Analysis in Sample 3 and Sample 4.

#### Predictions of recovered sample 3

```{r}
set.seed(1234)
# Predicting Sample 3 using the Random forest Model 
recovered.sample3$Brand <-predict(Brand_randomForest_MDL,recovered.sample3)

# final Predictions: 

sample3_Pred <- data.frame(merge(recovered.sample3,AllBrand_randomForest_mdl_Accr1,by="Brand"))

sample3_values <- sample3_Pred %>% 
      group_by(Brand) %>%
      summarise(Predicted_value=sum(accuracy_percent))

# Finding the brand 
Brand.Sample3 <- sample3_values[order(sample3_values$Predicted_value),]
Brand.Sample3<- tail(Brand.Sample3, n=5)
Brand.Sample3

# Testing the other models to confirm our results
RamshotEnforcer.accr<- Accuracy_by_Brand %>% 
  filter(Accuracy_by_Brand$Brand == "RamshotEnforcer")
#RamshotEnforcer.accr

#Implementing LDA
# Predicting Sample 3 using the Random forest Model 
LDA_sample3<-predict(Brand_LDA_MDL2,recovered.sample3)

Lda_sample3_N <- data.frame(LDA_sample3$class)

LDA_sample.3 <- Lda_sample3_N %>% 
      group_by(LDA_sample3.class) %>%
      summarise(Predicted_value=n())

# Finding the brand 
LDA_Brand.Sample3 <- LDA_sample.3[order(LDA_sample.3$Predicted_value),]
LDA_Brand.Sample3<- tail(LDA_Brand.Sample3, n=5)
LDA_Brand.Sample3

#Implementing Random Forest for Shape 

# Predicting Sample 3 using the Random forest Model 
randomforest_Shape_sample3 <- data.frame(predict(Shape_randomforest_MDL,recovered.sample3))

randomforest_Shape_sample3_values <- randomforest_Shape_sample3 %>% 
      group_by(predict.Shape_randomforest_MDL..recovered.sample3.) %>%
      summarise(Predicted_value=n())

randomforest_Shape_sample3_values 



```

Based on the results from the selected Random Forest model recovered sample 3 has the highest predicted value of 61 and is from Brand RamshotEnforcer. We validated our results by implementing the LDA Model and the predicted value of RamshotEnforcer is the highest with LDA as well. We checked sample 3 for the presence of other brands and both Random Forest and LDA showed the presence of other brands AmericanSelect, AccurateNo.2, and Accurate4100.To further confirm our results we predicted the shape of the recovered sample 3 and the sample have a spherical and flake shape. This confirmed our analysis that manufacturers are using multiple brands in the recovered sample 3, but the majority of particles are from the brand RamshotEnforcer.

#### Predictions of recovered sample 4

```{r}
set.seed(1234)
# Predicting Sample 4 using the Random forest Model 
recovered.sample4$Brand <-predict(Brand_randomForest_MDL,recovered.sample4)

# final Predictions: 

sample4_Pred <- data.frame(merge(recovered.sample4,AllBrand_randomForest_mdl_Accr1,by="Brand"))

sample4_values <- sample4_Pred %>% 
      group_by(Brand) %>%
      summarise(Predicted_value=sum(accuracy_percent))
sample4_values  <-  sample4_values[!is.na(sample4_values$Predicted_value), ]

# Finding the brand 
Brand.Sample4 <- sample4_values[order(sample4_values$Predicted_value),]
Brand.Sample4<- tail(Brand.Sample4, n=5)
Brand.Sample4

# Testing the other models to confirm our results
RamshotEnforcer.accr<- Accuracy_by_Brand %>% 
  filter(Accuracy_by_Brand$Brand == "RamshotEnforcer")
#RamshotEnforcer.accr

#Implementing LDA
# Predicting Sample 4 using the Random forest Model 
LDA_sample4<-predict(Brand_LDA_MDL2,recovered.sample4)
Lda_sample4_N <- data.frame(LDA_sample4$class)

LDA_sample.4 <- Lda_sample4_N %>% 
      group_by(LDA_sample4.class) %>%
      summarise(Predicted_value=n())
LDA_sample.4  <-  LDA_sample.4[!is.na(LDA_sample.4$Predicted_value), ]

# Finding the brand 
LDA_Brand.Sample4 <- LDA_sample.4[order(LDA_sample.4$Predicted_value),]
LDA_Brand.Sample4<- tail(LDA_Brand.Sample4, n=5)
LDA_Brand.Sample4

#Implementing Random Forest for Shape 

# Predicting Sample 4 using the Random forest Model 
randomforest_Shape_sample4 <- data.frame(predict(Shape_randomforest_MDL,recovered.sample4))

randomforest_Shape_sample4_values <- randomforest_Shape_sample4 %>% 
      group_by(predict.Shape_randomforest_MDL..recovered.sample4.) %>%
      summarise(Predicted_value=n())

randomforest_Shape_sample4_values

```

Based on the results from the selected Random Forest model recovered sample 4 has the highest predicted value of 71 and is from Brand RamshotEnforcer. We validated our results by implementing the LDA Model and the predicted value of RamshotEnforcer is the highest with LDA as well. We checked sample 4 for the presence of other brands and both Random Forest and LDA showed the presence of other brands AccurateNo.2, Accurate4100 & BL-C(2).To further confirm our results we predicted the shape of the recovered sample 4 and the sample have spherical and flattened_spherical shape. This confirmed our analysis that manufacturers are using multiple brands in the recovered sample 4, but the majority of the particles are from the brand RamshotEnforcer.

#### Creating a table of final results of prediction of all recovered samples:

```{r}
# Creating a Table for the final results for Brand Sample 1 & Sample2 

Recovered_Sample_Results <- data.frame(cbind(Models = c("RandomForest", "LDA"),
                                       Recovered.Sample1          = (c("RedDot", "RedDot")),
                                       Recovered.Sample2          = (c("RedDot", "RedDot"))))
                                       
kable(Recovered_Sample_Results , caption = "Recovered Sample Brand Prediction Results Sample1 & sample2 ")

# Prediction of recovered Sample 3 & 4 in a table 

Brand.Sample3$Ranforest.Sample3Brand <- Brand.Sample3$Brand
LDA_Brand.Sample3$Brand <- LDA_Brand.Sample3$LDA_sample3.class
Brand_sample3 <- data.frame(merge(x=Brand.Sample3,y= LDA_Brand.Sample3,by="Brand"))
Brand.Sample4$Ranforest.Sample4Brand <- Brand.Sample4$Brand
LDA_Brand.Sample4$Brand <- LDA_Brand.Sample4$LDA_sample4.class
Brand_sample4 <- data.frame(merge(x=Brand.Sample4,y= LDA_Brand.Sample4,by="Brand"))

# Merging to create the final table for Sample 3 and 4. 

Final_Brand_Results <- data.frame(full_join(x=Brand_sample3,y= Brand_sample4,by="Brand"))
Final_Brand_Resultstable = subset(Final_Brand_Results , select = c(Ranforest.Sample3Brand,LDA_sample3.class,Ranforest.Sample4Brand, LDA_sample4.class ))
Final_Brand_Resultstable 

# Creating a Table for the final results for shape

Recovered_Sample_Shape_Results <- data.frame(cbind(Models = c("RandomForest"),
                                       Recovered.Sample1          = (c("Flake")),
                                       Recovered.Sample2          = (c("Flake")),
                                       Recovered.Sample3          = (c("Spherical, Flake")), 
                                       Recovered.Sample4          = (c("spherical, flattened_spherical"))))
                                       
kable(Recovered_Sample_Shape_Results , caption = "Recovered Sample Shape Prediction Results")
```

Conclusion: The results above indicate that Recovered Sample 1 and Sample 2 are from the same brand ("RedDot"). The table for samples 3 and 4 shows that manufacturers are using multiple brands in the samples. For sample 3, the presence of the following brands Accurate4100, AccurateNo.2, AmericanSelect & RamshotEnforcer are there and in sample 4 Accurate4100, AccurateNo.2, BL-C(2) & RamshotEnforcer brands are found. The majority of the particles are from the brand "RamshotEnforcer" in sample 3 and sample 4 and the common brands in both sample 3 and sample 4 are Accurate4100, AccurateNo.2 & RamshotEnforcer.

#### Final Step Exporting the Predictions

```{r}

# Writing the final prediction in xlsx file.

library(writexl)

# Exporting Recovered Sample1 with predictions
write_xlsx(recovered.sample1, "C:/Users/divan/Desktop/STAT602 - FINAL SEMESTER/Group1_Final_Project_APRIL2023/Predicted_Recovered_Sample1.xlsx")

# Exporting Recovered Sample2 with predictions
write_xlsx(recovered.sample2, "C:/Users/divan/Desktop/STAT602 - FINAL SEMESTER/Group1_Final_Project_APRIL2023/Predicted_Recovered_Sample2.xlsx")

# Exporting Recovered Sample3 with predictions
write_xlsx(recovered.sample3, "C:/Users/divan/Desktop/STAT602 - FINAL SEMESTER/Group1_Final_Project_APRIL2023/Predicted_Recovered_Sample3.xlsx")

# Exporting Recovered Sample4 with predictions
write_xlsx(recovered.sample4, "C:/Users/divan/Desktop/STAT602 - FINAL SEMESTER/Group1_Final_Project_APRIL2023/Predicted_Recovered_Sample4.xlsx")

```

***Reference:***

1.  James, G., Witten, D., Hastie, T., & Tibshirani, R. (2021). An Introduction to Statistical Learning with Applications in R (2nd ed., p. 612). Springer. <https://hastie.su.domains/ISLR2/ISLRv2_website.pdf>
2.  Wickham, H., Chang, W., & Henry, L. (n.d.). A box and whiskers plot (in the style of Tukey). ggplot2.tidyverse. Retrieved 10 March 2023, from <https://ggplot2.tidyverse.org/reference/geom_boxplot.html>
3.  Statistics Globe (n.d.). Draw multiple Boxplots in one graph.statisticsglobe .Retrieved 10 March 2023, from <https://statisticsglobe.com/draw-multiple-boxplots-in-one-graph-in-r>
4.  GGPLOT2 histogram plot : Quick Start Guide - R Software and Data Visualization. STHDA. (n.d.). Retrieved April 22, 2023, from <http://www.sthda.com/english/wiki/ggplot2-histogram-plot-quick-start-guide-r-software-and-data-visualization>
5.  ggplot2 barplots : Quick start guide - R software and data visualization - Easy Guides - Wiki - STHDA. (2019). Sthda.com. <http://www.sthda.com/english/wiki/ggplot2-barplots-quick-start-guide-r-software-and-data-visualization>
6.  Zach. (2022, August 3). How to Perform a Two Sample T-Test in R. Statology. Retrieved April 22, 2023, from <https://www.statology.org/two-sample-t-test-in-r/>
7.  Bevans, R. (2022). ANOVA in R \| A Complete Step-by-Step Guide with Examples. Scribbr.Retrieved April 22, 2023, from <https://www.scribbr.com/statistics/anova-in-r/>
8.  Kruskal-Wallis Test \| R Tutorial. (n.d.). Chi Yau. scribbr. Retrieved April 22, 2023, from <https://www.r-tutor.com/elementary-statistics/non-parametric-methods/kruskal-wallis-test>
9.  Z. (2022, April 12). How to Split Data into Training & Test Sets in R. Statology. Retrieved March 11, 2023, from <https://www.statology.org/train-test-split-r/>
10. R: How to split a data frame into training, validation, and test sets?, Stack Overflow. Retrieved March 11, 2023, from <https://stackoverflow.com/questions/36068963/r-how-to-split-a-data-frame-into-training-validation-and-test-sets>.
11. (n.d.). Associations between Variables. Codecademy. Retrieved March 11, 2023, from <https://www.codecademy.com/learn/stats-associations-between-variables/modules/stats-associations-between-variables/cheatsheet>
12. Z. (2020, October 30). Linear Discriminant Analysis in R (Step-by-Step). Statology. Retrieved March 11, 2023, from <https://www.statology.org/linear-discriminant-analysis-in-r/>
13. Sarkar, Priyankur. "What Is LDA: Linear Discriminant Analysis for Machine Learning." What Is Linear Discriminant Analysis (LDA)?, Knowledgehut, 27 Dec. 2022, <https://www.knowledgehut.com/blog/data-science/linear-discriminant-analysis-for-machine-learning>.
14. Z. (2020, November 2). Quadratic Discriminant Analysis in R (Step-by-Step). Statology. Retrieved March 12, 2023, from <https://www.statology.org/quadratic-discriminant-analysis-in-r/>
15. Saunders, C. (2023, February 10). Classification Part 2 LDA and QDA [Lecture]. D2l.Sdbor.edu. <https://d2l.sdbor.edu/d2l/le/content/1781558/viewContent/11116132/View>
16. Finnstats. (2021, April 13). Random Forest in R: R-bloggers. R. Retrieved April 22, 2023, from <https://www.r-bloggers.com/2021/04/random-forest-in-r/>
17. Fraley, C., Raftery, A. E., & Scrucca, L. (n.d.). MclustDA discriminant analysis. Mclust-Org.Github. Retrieved March 13, 2023, from <https://mclust-org.github.io/mclust/reference/MclustDA.html>
18. [shanem\@mtu.edu](mailto:shanem@mtu.edu){.email}, Shane T. Mueller. Model-Based Clustering and Mclust, 28 Mar. 2021, <https://pages.mtu.edu/~shanem/psy5220/daily/Day19/modelbasedclustering.html#content>.
19. Saunders, C. (2023, February 24). MclustDA part1 [Lecture]. D2l.Sdbor.edu. <https://d2l.sdbor.edu/d2l/le/content/1781558/viewContent/11116023/View>
20. Saunders, C. (2023, February 24). MclustDA part2 [Lecture]. D2l.Sdbor.edu. <https://d2l.sdbor.edu/d2l/le/content/1781558/viewContent/11116022/View>
21. Saunders, C. (2023, February 24). MclustDA part3 Cross validation [Lecture]. D2l.Sdbor.edu. <https://d2l.sdbor.edu/d2l/le/content/1781558/viewContent/11116024/View>
22. Saunders, C. (2023, February 24). Mclust Play Part2 R file [Lecture]. D2l.Sdbor.edu. <https://d2l.sdbor.edu/d2l/le/content/1781558/viewContent/11116026/View>
23. Saunders, C. (2023, February 24). Mclust Play Part3 R file [Lecture]. D2l.Sdbor.edu. <https://d2l.sdbor.edu/d2l/le/content/1781558/viewContent/11116025/View>
24. kTable: Make Nicely Formatted Tables in Kmisc: Kevin Miscellaneous. (n.d.). Rdrr.io. Retrieved April 25, 2023, from <https://rdrr.io/cran/Kmisc/man/kTable.html>
25. Chat.openai.com, <https://chat.openai.com/>.
